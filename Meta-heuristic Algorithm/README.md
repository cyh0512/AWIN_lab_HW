超啟發式演算法(Meta-heuristic Algorithm)：

A.動態規劃(Dynamic programming)： 動態程式規劃算法可以將背包問題，由下到上，找出不同大小問題的optimal substructure， ，把小問題的解組合成大問題的解。 此算法必定可以找到整個0-1背包問題的最佳組合，但程式的空間耗費也較大。

B.爬山演算法(Hill climbing, HC)： 爬山演算法先從最初的可行解，去尋找鄰近的下一個可行解， 我的方法是每次隨機一個整數且不大於物品數， 如果該整數對應的物品，放入背包後沒有超重，則此可行解就會比原先解還要好， 不斷重複，直到500次迭代之後，將能找到的最佳解輸出。 此算法有機會找到不錯的解，但因為放入背包後就不會再放棄該物品， 所以能找到的最佳解通常比動態程式規劃及模擬退火法還要差。 (例如取一物品重量為最高、價值為最低，但不超重，仍會將其放入背包且不會再取出， 會讓其他更高價值的物品無法放入背包， 以數學的角度來說，物品放入後不取出的方法，會讓此問題慢慢陷入局部解空間之中， 而無法從中跳出，這時找到的局部最佳解不一定會等於問題的整體最佳解)

C.模擬退火演算法(Simulated annealing, SA)： 模擬退火演算法從最初的可行解開始，每次隨機選擇一物品，可分為兩種情況： 

I.如果該物品已經放入背包則從中取出，必定得到一可行解比原先的解還要差。 

II.如果該物品不在背包內，且放入後不超重，則將其放入背包，得到一可行解比原先的解還要好， 若此解比目前找到的最佳解還要好，則將其更新。 
此算法不一定能找到整體的最佳解，但對比爬山演算法，模擬退火法有接受較差可行解的特性， 故可以搜尋較多的局部解區域，從數個局部最佳解之中，找出近似整體最佳解的可行解。 其中，退火函數我選擇T=c*T，在每次迭代，將溫度乘上一個0到1之間的常數，使溫度隨迭代次數降低，同時讓接受更差可行解的機率逐漸降低， 這在一開始給了程式很高的機率，來跳脫目前的局部解區域， 而隨著迭代次數增加，可探索的局部解區域會漸漸地收斂，最後停在目前的局部最佳解。
在題目給定的迭代次數=500及物品數量=15等等條件下， 我發現以c=0.9999作為退火函數T=c*T的常數項，效果最好， 平均在200-300迭代後，就能找到足夠好的可行解。 所以使用模擬退火演算法，如果參數選擇的好，可能比動態程式規劃來得快且足夠接近最佳解。

另外，在此模擬退火演算法中，我認為有缺失並且可改進的地方， 為了閱讀方便，以下將"目前所在的局部最佳解"簡稱為"A"。而將"目前所找到的最佳解"簡稱為"B"。
在演算法後期，因為模擬退火使溫度降低，會讓接受更差可行解的機率降低，導致此算法不容易跳脫"A"區域，被迫在目前的局部解空間中繼續尋找"A"。 但程式可能因為先前曾接受跳脫局部解空間，而讓"A"與"B"越差越遠，較難經由剩餘的迭代次數跳回到"B"。 我認為可以記錄找到"B"當下的物品組合，然後在大約第300~400次迭代設置逃脫點(根據本題經驗，平均在200-300迭代後，就能找到足夠好的可行解)， 此時如果"A"與"B"的解空間相差太遠(可能是物品組合的0-1序列差異太大)，就放棄"B"並跳脫到"A"，在剩餘的迭代次數內，在"A"空間中盡可能找到更好的解。 這樣就能在不增加迭代次數的情況下，找到比原先更優的可行解。
